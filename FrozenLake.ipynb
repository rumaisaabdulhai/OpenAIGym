{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning With Frozen Lake\n",
    "\n",
    "By Rumaisa Abdulhai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "from gym.envs.registration import register\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Discrete(16)\n",
      "Action space: Discrete(4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gym.spaces.discrete.Discrete"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_name = \"FrozenLakeNoSlip-v0\"\n",
    "custom_map = [\"SFFF\", \n",
    "              \"FHFH\", \n",
    "              \"FFFH\", \n",
    "              \"HFFG\"]\n",
    "\n",
    "try:\n",
    "    register(\n",
    "        id='FrozenLakeNoSlip-v0',\n",
    "        entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "        kwargs={'is_slippery':False},\n",
    "        max_episode_steps=100,\n",
    "        reward_threshold=0.78, # optimum = .8196\n",
    "    )\n",
    "except:\n",
    "    pass\n",
    "\n",
    "env = gym.make(env_name, desc = custom_map)\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "print(\"Action space:\", env.action_space)\n",
    "type(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, env):\n",
    "        '''\n",
    "        Constructor for the Agent object\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        self: The Agent object\n",
    "        env: The OpenAI environment\n",
    "        '''\n",
    "        self.is_discrete = \\\n",
    "            type(env.action_space) == gym.spaces.discrete.Discrete\n",
    "        \n",
    "        if self.is_discrete:\n",
    "            self.action_size = env.action_space.n\n",
    "            print(\"Action size:\", self.action_size)\n",
    "        else:\n",
    "            self.action_low = env.action_space.low\n",
    "            self.action_high = env.action_space.high\n",
    "            self.action_shape = env.action_space.shape\n",
    "            print(\"Action range:\", self.action_low, self.action_high)\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        if self.is_discrete:\n",
    "            action = random.choice(range(self.action_size))\n",
    "        else:\n",
    "            action = np.random.uniform(self.action_low,\n",
    "                                       self.action_high,\n",
    "                                       self.action_shape)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAgent(Agent):\n",
    "    \n",
    "    def __init__(self, env, discount_rate=0.97, learning_rate=0.01):\n",
    "        '''\n",
    "        Constructor for the QAgent object\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        self: The QAgent object\n",
    "        env: The OpenAI environment\n",
    "        discount_rate: The discount rate\n",
    "        learning_rate: The learning rate\n",
    "        '''\n",
    "        super().__init__(env)\n",
    "        self.state_size = env.observation_space.n\n",
    "        print(\"State size:\", self.state_size)\n",
    "        \n",
    "        self.epsilon = 1.0\n",
    "        self.discount_rate = discount_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.q_table = 1e-4 * np.random.random([self.state_size, self.action_size])\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        '''\n",
    "        Generates a random number between 0.0 \n",
    "        and 1.0 inclusive. If the number is less \n",
    "        than epsilon, returns a random action, \n",
    "        else returns the action with the max q.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        self: The QAgent object\n",
    "        state: The current state\n",
    "        '''\n",
    "        if random.random() < self.epsilon:\n",
    "            return super().get_action(state)\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state])\n",
    "    \n",
    "    def train(self, experience):\n",
    "        '''\n",
    "        Trains the agent\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        self: The QAgent object\n",
    "        experience: Info about a step\n",
    "        '''\n",
    "        state, action, next_state, reward, done = experience\n",
    "        \n",
    "        q_next = self.q_table[next_state]\n",
    "        q_next = np.zeros([self.action_size]) if done else q_next\n",
    "        q_target = reward + self.discount_rate * np.max(q_next)\n",
    "        \n",
    "        delta_q = q_target - self.q_table[state,action]\n",
    "        self.q_table[state,action] += self.learning_rate * delta_q\n",
    "        \n",
    "        if done:\n",
    "            self.epsilon *= 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action size: 4\n",
      "State size: 16\n"
     ]
    }
   ],
   "source": [
    "# Creates the agent\n",
    "agent = QAgent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reward = 0\n",
    "rounds = 5\n",
    "num_eps = 100\n",
    "\n",
    "def run(rounds, num_eps, total_reward):\n",
    "\n",
    "    for i in range(1, rounds + 1):\n",
    "\n",
    "        for ep in range(1, num_eps + 1):\n",
    "            state = env.reset()\n",
    "            done = False\n",
    "            while not done:\n",
    "                action = agent.get_action(state)\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                agent.train((state,action,next_state,reward,done))\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "\n",
    "                print(\"Round\", i)\n",
    "                print(\"s:\", state, \"a:\", action)\n",
    "                print(\"Episode: {}, Total reward: {}, eps: {}\".format(ep,total_reward,agent.eps))\n",
    "                env.render()\n",
    "                print(agent.q_table)\n",
    "                time.sleep(0.05)\n",
    "                clear_output(wait=True)\n",
    "\n",
    "        total_reward = 0\n",
    "        \n",
    "# run(rounds, num_eps, total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame, sys\n",
    "\n",
    "SCREEN_WIDTH = 480\n",
    "SCREEN_HEIGHT = 480\n",
    "\n",
    "NUM_BLOCKS_WIDE = 4\n",
    "NUM_BLOCKS_HIGH = 4\n",
    "BLOCK_HEIGHT = round(SCREEN_HEIGHT/NUM_BLOCKS_HIGH)\n",
    "BLOCK_WIDTH = round(SCREEN_WIDTH/NUM_BLOCKS_WIDE)\n",
    "\n",
    "BLACK = (0, 0, 0)\n",
    "START = (153, 184, 152)\n",
    "GOAL = (232, 74, 95)\n",
    "HOLE = (27, 38, 44)\n",
    "FROZEN = (50, 130, 184)\n",
    "\n",
    "TITLE = \"Frozen Lake\"\n",
    "\n",
    "def state_to_pos(state):\n",
    "    '''\n",
    "    Converts a state to a \n",
    "    matrix position\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    state (int): The current state\n",
    "    '''\n",
    "    count = 0\n",
    "    matrix = []\n",
    "    \n",
    "    for x in range(len(custom_map)):\n",
    "        row = []\n",
    "        for y in range(len(custom_map[0])):\n",
    "            row.append(count)\n",
    "            count+=1\n",
    "        matrix.append(row)\n",
    "    \n",
    "    for i in range(len(custom_map)):\n",
    "        for j in range(len(custom_map[0])):\n",
    "            if matrix[i][j] == state:\n",
    "                pos = (i, j)\n",
    "    \n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 5\n",
      "s: 15 a: 2\n",
      "Episode: 100, Total reward: 99.0, eps: 0.006570483042414605\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "[[1.15846032e-04 9.59576022e-02 6.81227131e-05 6.28162664e-04]\n",
      " [9.92957575e-05 3.29015141e-05 8.71721865e-05 4.12594637e-05]\n",
      " [3.49169731e-05 2.85710796e-05 5.38673025e-05 7.76537166e-05]\n",
      " [5.04956376e-05 1.45550249e-05 6.24590927e-05 6.98008799e-05]\n",
      " [1.10818558e-03 2.01919119e-01 3.40809929e-05 3.67649703e-04]\n",
      " [8.64388570e-05 6.99179817e-05 1.36110625e-05 2.38237955e-05]\n",
      " [3.84167022e-05 2.38772788e-02 6.18024506e-05 6.57518568e-05]\n",
      " [4.56255933e-05 8.81120976e-05 2.52414063e-05 7.41331014e-05]\n",
      " [4.52601413e-03 4.20071787e-07 3.72786576e-01 6.79928737e-04]\n",
      " [1.89665597e-03 6.87416184e-04 5.93698241e-01 6.25323383e-05]\n",
      " [2.76328855e-03 8.11272879e-01 3.94198644e-05 4.00933073e-04]\n",
      " [6.68979573e-05 4.42978369e-05 4.66740003e-05 5.97541715e-05]\n",
      " [7.42957272e-05 6.82973995e-05 3.57044220e-05 2.18380871e-05]\n",
      " [2.15030844e-05 3.66884790e-05 4.82714517e-02 9.75039482e-06]\n",
      " [1.08527185e-03 1.87852176e-02 9.61473427e-01 1.35031037e-02]\n",
      " [1.92386866e-05 1.60705542e-05 3.07818324e-05 7.86061637e-05]]\n"
     ]
    }
   ],
   "source": [
    "def get_tile_color(tile):\n",
    "    '''\n",
    "    Gets the tile color\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tile (str): The tile\n",
    "    '''\n",
    "    if tile == \"S\":\n",
    "        color = START\n",
    "    elif tile == \"G\":\n",
    "        color = GOAL\n",
    "    elif tile == \"H\":\n",
    "        color = HOLE\n",
    "    elif tile == \"F\":\n",
    "        color = FROZEN\n",
    "    else:\n",
    "        color = BLACK\n",
    "    return color\n",
    "\n",
    "def draw_map(surface, map_tiles):\n",
    "    '''\n",
    "    Draws the map\n",
    "    '''\n",
    "    for j, tile in enumerate(map_tiles):\n",
    "        for i, tile_contents in enumerate(tile):\n",
    "            # print(\"{},{}: {}\".format(i, j, tile_contents))\n",
    "            myrect = pygame.Rect(i * BLOCK_WIDTH, j * BLOCK_HEIGHT, BLOCK_WIDTH, BLOCK_HEIGHT)\n",
    "            pygame.draw.rect(surface, get_tile_color(tile_contents), myrect)\n",
    "\n",
    "def draw_grid(surface):\n",
    "    '''\n",
    "    Draws the grid\n",
    "    '''\n",
    "    for i in range(NUM_BLOCKS_WIDE):\n",
    "        new_height = round(i * BLOCK_HEIGHT)\n",
    "        new_width = round(i * BLOCK_WIDTH)\n",
    "        pygame.draw.line(surface, BLACK, (0, new_height), (SCREEN_WIDTH, new_height), 2)\n",
    "        pygame.draw.line(surface, BLACK, (new_width, 0), (new_width, SCREEN_HEIGHT), 2)\n",
    "\n",
    "def game_loop(surface):\n",
    "    \n",
    "    total_reward = 0\n",
    "    rounds = 5\n",
    "    num_eps = 100\n",
    "\n",
    "    for i in range(1, rounds + 1):\n",
    "\n",
    "        for ep in range(1, num_eps + 1):\n",
    "                    \n",
    "            state = env.reset()\n",
    "            done = False\n",
    "            while not done:\n",
    "                \n",
    "                for event in pygame.event.get():\n",
    "                    if event.type == pygame.QUIT:\n",
    "                        pygame.quit()\n",
    "                        sys.exit()\n",
    "                    if event.type == pygame.KEYDOWN:\n",
    "                        if event.key == pygame.K_ESCAPE:\n",
    "                            pygame.quit()\n",
    "                            sys.exit()\n",
    "                action = agent.get_action(state)\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                agent.train((state,action,next_state,reward,done))\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "\n",
    "                print(\"Round\", i)\n",
    "                print(\"s:\", state, \"a:\", action)\n",
    "                print(\"Episode: {}, Total reward: {}, eps: {}\".format(ep,total_reward,agent.epsilon))\n",
    "                env.render()\n",
    "                print(agent.q_table)\n",
    "                time.sleep(0.05)\n",
    "                clear_output(wait=True)\n",
    "                \n",
    "                draw_map(surface, read_map(state_to_pos(state)))\n",
    "                draw_grid(surface)\n",
    "                pygame.display.update()\n",
    "\n",
    "        total_reward = 0\n",
    "\n",
    "def initialize_game():\n",
    "    pygame.init()\n",
    "    surface = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "    pygame.display.set_caption(TITLE)\n",
    "    surface.fill(BLACK)\n",
    "    return surface\n",
    "\n",
    "def read_map(state_pos):\n",
    "    '''\n",
    "    Reads the map\n",
    "    '''\n",
    "    \n",
    "    world_map = custom_map      \n",
    "    world_map = []\n",
    "    for row in custom_map:\n",
    "        world_map.append(list(row))\n",
    "        \n",
    "    world_map[state_pos[0]][state_pos[1]] = \"X\"\n",
    "    \n",
    "    new_map = []\n",
    "    for row in world_map:\n",
    "        string = \"\"\n",
    "        for ele in row:\n",
    "            string += ele\n",
    "        new_map.append(string)\n",
    "                \n",
    "    return new_map\n",
    "\n",
    "def main():\n",
    "    world_map = custom_map\n",
    "    surface = initialize_game()\n",
    "    game_loop(surface)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
